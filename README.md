
# ðŸŒ EnviroScan AI 

EnviroScan AI is a proof-of-concept platform that demonstrates the power of machine learning in environmental science. It provides actionable insights into the sources of air pollution by analyzing real-time air quality data, weather patterns, and geospatial information.

## ðŸš€ Live Demo
Check out the deployed app here:  
[EnviroScan AI Web App](https://enviroscanai-kche9zywaakhvqwrcgcezc.streamlit.app/)

https://github.com/user-attachments/assets/4851c79d-62fb-4e3b-a90c-d88e19663952











## ðŸ“– Project Overview
EnviroScan AI aims to go beyond measuring pollution levels by attributing pollution events to specific sources such as:
- Vehicular traffic
- Industrial activity
- Agricultural burning  

**Target Users:**
- Urban Planners & Policymakers  
- Environmental Agencies  
- Researchers & Students  

---

## ðŸ”¬ Methodology

### 1. Data Pipeline
- **Ingestion:** Collect air quality metrics (PMâ‚‚.â‚…, NOâ‚‚, SOâ‚‚), meteorological data, and geospatial features.  
- **Preprocessing:** Clean data, handle missing values, and create time-based features.  
- **Labeling:** Rule-based engine assigns preliminary `pollution_source` labels for supervised learning.  
- **Train/Test Split:** Data is split into training and testing sets for evaluation.  

### 2. Model Training & Evaluation
- **Algorithm:** Ensemble Voting Classifier combining:
  - **Random Forest Classifier (RF)**
  - **XGBoost Classifier (XGB)**
- **Why Ensemble Voting?**
  - Combines strengths of multiple models for higher accuracy
  - Reduces overfitting compared to single models
  - Handles non-linear relationships and complex feature interactions
  - Supports multi-class evaluation with classification metrics

**Evaluation Metrics:**
- Classification report (precision, recall, F1-score for each pollution source class)  
- Confusion matrix (visual analysis of predictions)  

**Model Output:**
- Ensemble model saved as `outputs/ensemble_model.joblib`  
- Label encoder saved as `config.ENCODER_FILE`  
- Evaluation report saved as `outputs/ensemble_model_report.txt`
 

---

## ðŸ’» Technology Stack
- **Python:** Core backend language  
- **Streamlit:** Web app and dashboard  
- **Scikit-learn:** Machine learning models  
- **Pandas:** Data processing and analysis  
- **Folium & Streamlit-Folium:** Interactive geospatial maps  
- **Plotly & Seaborn:** Charts and visualizations  
- **Joblib:** Model serialization  
- **Python-dotenv:** Managing API keys  

---

## âš™ï¸ How to Run This Project

### Windows

```bash
# 1. Clone repository
git clone https://github.com/Supriyo760/enviroscan.Ai
cd EnviroScan-Project

# 2. Setup environment
=======
How to Run this Project:- 
Step by Step commands :-
---------------------------------
Windows:-
:: 1. Clone repository
git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME.git
cd YOUR_REPOSITORY_NAME

:: 2. Setup environment
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

# 3. Add API key
notepad .env
# Add this line:
OPENWEATHER_API_KEY=your_key_here

# 4. Run data pipeline
python run_pipeline.py

# 5. Start Streamlit app
streamlit run app.py
````

### MacOS / Linux

```bash
# 1. Clone repository
git clone https://github.com/Supriyo760/enviroscan.Ai
cd EnviroScan-Project
=======
:: 3. Add API key
notepad .env
:: Add this line: OPENWEATHER_API_KEY=your_key_here

:: 4. Run pipeline
python3 run_pipeline.py

:: 5. Start app
streamlit run app.py
-------------------------------------------------------------------------
 Mac os users:-
# 1. Clone repository
git clone https://github.com/YOUR_USERNAME/YOUR_REPOSITORY_NAME.git
cd YOUR_REPOSITORY_NAME

# 2. Setup environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. Add API key
echo "OPENWEATHER_API_KEY=your_key_here" > .env

<<<<<<< HEAD
# 4. Run data pipeline
python3 run_pipeline.py

# 5. Start Streamlit app
streamlit run app.py
```

### Troubleshooting Dependencies

If some packages fail to install, try installing them individually:

```bash
pip install streamlit pandas scikit-learn xgboost
pip install folium streamlit-folium plotly
pip install requests osmnx python-dotenv joblib
```

---

## ðŸ“‚ Repository Structure

```
EnviroScan-AI-Powered-Team-6/
â”‚
â”œâ”€â”€ app.py                       # Main Streamlit app entry point
â”œâ”€â”€ run_pipeline.py              # Script to run the entire data pipeline
â”œâ”€â”€ EnviroScan.py                # Possibly main project logic / module
â”œâ”€â”€ train_model.py               # Script for training the ML model
â”œâ”€â”€ config.py                    # Configuration file for constants, paths, etc.
â”œâ”€â”€ requirements.txt             # Project dependencies
â”œâ”€â”€ .env                         # Environment variables (API keys)
â”œâ”€â”€ enviroscan.log               # Log file for the project
â”œâ”€â”€ How_to_run_program_file       # Instructions / script guide
â”œâ”€â”€ my_script_code.txt           # Any additional code snippets
â”œâ”€â”€ README.md                    # Project documentation
â”‚
â”œâ”€â”€ pages/                       # Streamlit multi-page app scripts
â”‚   â”œâ”€â”€ About.py
â”‚   â”œâ”€â”€ Live_Prediction.py
â”‚   â”œâ”€â”€ Pollution_Dashboard.py
â”‚   â””â”€â”€ image.png                # Image used in About page
â”‚
â”œâ”€â”€ scripts/                     # Scripts for data pipeline and ML preprocessing
â”‚   â”œâ”€â”€ 01_data_collection.py
â”‚   â”œâ”€â”€ 02_data_processing.py
â”‚   â”œâ”€â”€ 03_label_and_split.py
â”‚   â”œâ”€â”€ 04_train_model.py
â”‚   â””â”€â”€ __pycache__/             # Python cache folder
â”‚
â”œâ”€â”€ venv/                        # Python virtual environment
â”‚
â”œâ”€â”€ data/ (optional, if exists)  # Raw / processed datasets
â”‚   â””â”€â”€ locations.csv
â”‚
â”œâ”€â”€ outputs/                     # Any output files, models, or results
â”‚
â””â”€â”€ cache/                       # Streamlit or project cache files

```

---

## ðŸ“ License

This project is open-source. Feel free to use, modify, and share under the [MIT License](LICENSE).

---

=======
# 4. Run pipeline
python3 scripts/run_pipeline.py

# 5. Start app
streamlit run app.py
-----------------------------------------------------------------------------
others:-
    
If dependencies fail to install:
# Try installing individually
pip install streamlit pandas scikit-learn xgboost
pip install folium streamlit-folium plotly
pip install requests osmnx python-dotenv joblib


